\documentclass[titlepage,a4paper]{article}

\usepackage{bbm}
\usepackage{a4wide}
\usepackage[colorlinks=true,linkcolor=black,urlcolor=blue,bookmarksopen=true]{hyperref}
\usepackage{bookmark}
\usepackage{fancyhdr}
\usepackage[spanish]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{float}
\usepackage{tikz}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}


\pagestyle{fancy} % Encabezado y pie de página
\fancyhf{}
\fancyhead[R]{Resumen Probabilidad y Estadistica B - FIUBA}
\renewcommand{\headrulewidth}{0.4pt}
\fancyfoot[C]{\thepage}
\renewcommand{\footrulewidth}{0.4pt}

\begin{document}
\begin{titlepage} % Carátula
	\hfill\includegraphics[width=6cm]{logofiuba.jpg}
    \centering
    \vspace{20px}
    \newline
    
    \Huge \textbf{Probabilidad y Estadistica B}
    \vskip2cm
    \Large Resumen Probabilidad y Estadistica B\\
    Segundo cuatrimestre de 2021 
    
\end{titlepage}

\tableofcontents % Índice general
\newpage

\section{Axiomas de Probabilidad}

Una probabilidad es una funcion de P que a cada evento A le hace corresponder un numero real P(A) con las siguientes propiedades:
\begin{enumerate}
    \item $0 \leq P(A) \leq 1$ 
    \item $P(\Omega)$ = 1 
    \item $ A \cap B = \emptyset \Longrightarrow P(A \cap B) = P(A) + P(B)  $
    \item $P(\bar{A}) = 1  - P(A)$
\end{enumerate}

\section{Experimentos con resultados equiprobables}
\subsection{Laplace}
Evento $A$ con $M$ elementos y $\Omega$ espacio finito de $N$ elementos:
\begin{equation*}
    P(A) = \frac{M}{N} = \frac{card(A)}{card(\Omega)}
\end{equation*}

\section{Conteo}
\subsection{Regla del producto}
Sirve para conjunto de pares ordenados entre dos conjuntos $A$ y $B$: (cada uno de A con cada uno de B)
\begin{equation*}
    A \times  B = \{(a,b) : a \in A, b \in B \} = card(A) \cdot card(B)
\end{equation*}

\subsection{Permutaciones}
Sirve para saber de cuantas formas se pueden ordenar $n$ elementos de un conjunto:
\begin{equation*}
    n! = 1 \times 2 \times ...\times n
\end{equation*}

\subsection{Variaciones}
Sirve para subconjuntos ordenados de $k$ elementos, pertenecientes a un conjunto de $n$ elementos, se representa como $(n)_{k}$:
\begin{equation*}
    (n)_{k} = n(n-1) ... (n-k+1) = \frac{n!}{(n-k)!}
\end{equation*}
\textbf{OBS}: se hace con el boton $nPr$

\subsection{Combinaciones}
Sirve para subconjuntos sin ordenar de $k$ elementos, pertenecientes a un conjunto de $n$ elementos, se representa como $n \choose k$:
\begin{equation*}
    {n \choose k} = \frac{n!}{k!(n-k)!}
\end{equation*}
\textbf{OBS}: se hace con el boton $nCr$

\subsection{Bolas y urnas}
Sirve para bolas indistinguibles y urnas:
\begin{equation*}
    \# CP = {B+(U-1) \choose B}
\end{equation*}
\textbf{OBS}: se hace con el boton $nPr$

\section{Teoremas sobre conjuntos de eventos}

\subsection{Teorema 1}
Sea $A(n)$ una sucesion de eventos tales que $A_{n} \subset A_{n+1} \forall n$ y $A = \bigcup_{i=0}^{\infty} A_{i}$ :
\begin{equation*}
    P(A) = \lim_{n \to \infty } P(A_{n})
\end{equation*}


\subsection{Teorema 2}
Sea $A(n)$ una sucesion de eventos tales que $A_{n+1} \subset A_{n} \forall n$ y $A = \bigcap_{i=0}^{\infty} A_{i}$ :
\begin{equation*}
    P(A) = \lim_{n \to \infty } P(A_{n})
\end{equation*}

\subsection{Teorema $\sigma$-aditividad}
Sea $A = \bigcup_{i=0}^{\infty} A_{i} \in \mathcal{A} $ con los eventos $A_{i}$ mutuamente excluyentes 2 a 2, entonces:
\begin{equation*}
    P(A) = P(\bigcup_{i=0}^{\infty} A_{i}) = \sum_{i=1}^{\infty}P(A_{i})
\end{equation*}

\section{Relaciones entre dos eventos: probabilidad condicional e independencia}

\subsection{Probabilidad condicional}
Es la probabilidad que un evento $A$ se de, sabiendo que ya se dio el evento $B$ ($A$ dado $B$):
\begin{equation*}
    P(A|B) = \frac{P(A \cap B)}{P(B)}
\end{equation*}

\subsubsection*{Propiedades de la probabilidad condicional}
\begin{enumerate}
    \item $0 \leq P(A|B) \leq 1$, $\forall A \in \mathcal{A}$
    \item $P(\Omega|B) = 1$
    \item Si $A \cap C = \emptyset \rightarrow P(A \cup C | B) = P(A|B) + P(C|B)$ 
    \item Si $P(B) > 0$ :\begin{itemize}
        \item $P(A \cap B) = P(A|B)\cdot P(B) = P(B|A) \cdot P(A)$
        \item $P(A \cap B \cap C) = P(A|B \cap C) \cdot P(A|B) \cdot P(C) =P(A|B \cap C) \cdot P(B\cap C) $
    \end{itemize}
\end{enumerate}

\subsubsection*{Teorema de la probabilidad total}
Dada una particion de $\Omega$ en $B_{1},B_{2},...,B_{n}$ eventos, dado un evento superpuesto $A$, la probabilidad de $A$ es:
\begin{equation*}
    P(A) = \sum_{i=1}^{n} P(A|B_{i}) \cdot P(B_{i})
\end{equation*}

\subsection{Independencia de eventos}
Dos eventos son independientes cuando:
\begin{equation*}
    P (A \cap B) = P(A) \cdot P(B)
\end{equation*}
Esto implica que hay la misma proporcion de $B$ en $A$ que en todo $\Omega$ y viceversa.

\subsubsection*{Propiedades de la independencia de eventos}
\begin{enumerate}
    \item Si $A$ y $B$ son independientes, tambien lo son $\bar{A}$ y $B$, $A$ y $\bar{B}$, $\bar{A}$ y $\bar{B}$
    \item $A_{1},A_{2},...,A_{n}$ son independientes sii para cada subconjunto de mas de dos elementos, la interseccion de los sucesos coincide con el producto de las probabilidades.
\end{enumerate}


\subsection{Teorema de Bayes}
Sean $B_{1},B_{2},...,B_{k}$ una particion de $\Omega$, $A$ un evento de probabilidad positiva:
\begin{equation*}
    P(B_{i}|A) = \frac{P(A|B_{i}) \cdot P(B_{i})}{\sum_{j=1}^{k} P(A|B_{i}) \cdot P(B_{i})}
\end{equation*}
Se deduce de la definicion de probabilidad condicional y el teorema de probabilidad total.

\section{Variables aleatorias}
Sea ($\Omega, \mathcal{A}, P$) un espacio de probabilidad y $ \text{X: }\Omega \rightarrow \mathbb{R}$  una funcion, diremos que $X$ es una variable aleatoria si
$X^{-1}(B) \in \mathcal{A}$. Se puede calcular probabilidad como:
\begin{equation*}
    P(X^{-1}(B)) = P(X \in B)
\end{equation*}

\subsection{Funcion de distribucion}
Sea ($\Omega, \mathcal{A}, P$) un espacio de probabilidad y $X$ una V.A., definimos su \underline{funcion de distribucion}:
\begin{equation*}
    F_{X} (x) = P(X \leq x) \hspace{16px}  \forall x \in \mathbb{R}
\end{equation*}
Esta funcion se encarga de acumular probabilidad desde $-\infty$ hasta $x$.\\
\textbf{OBS}: $P(A < X \leq B) = F_{X}(B) - F_{X}(A)$
\subsubsection*{Propiedades de la funcion de distribucion}
\begin{enumerate}
    \item $F_{X} \in [0,1] \hspace{8px} \forall x \in \mathbb{R}$.
    \item $F_{X}$ es monotona np decreciente.
    \item $F_{X}$ es continua a derecha.
    \item $\lim_{x \to {-\infty}} F_{X}(x) = 0$ y $\lim_{x \to {+\infty}} F_{X}(x) = 1$
\end{enumerate}

\subsection{Soporte de una V.A}
El soporte de X es:
\begin{equation*}
    S_{X} = \{ x \in \mathbb{R} : F_{X}(x) - F_{X}(x^{-}) \neq 0 \vee \frac{dF_{X}(x)}{dx} \neq 0 \}
\end{equation*}

\subsection{Variables aleatorias discretas}
La variable $X$ tiene una distribucion discreta si hay un conjunto $A \in \mathbb{R}$ finito o infinito numerable, tal que $P(X \in A) = 1$.\\
Sea para cada $x \in A:$ $p_{X}(x) = P(X = x)$, se verifica que si $B \subset \mathbb{R}$: 
\begin{equation*}
    P(X \in B) = \sum_{x \in B \cap A} p_{X}(x)
\end{equation*}
Y en particular:
\begin{equation*}
    \sum_{x \in A} p_{X}(x) = 1 
\end{equation*}
Y la funcion de distribucion es dado un $B = (-\infty,t]$ resulta:
\begin{equation*}
    P(X \in B) = P(X \leq t) = F_{X}(t) = \sum_{x \leq t} p_{X}(x)
\end{equation*}

\subsection{Variables aleatorias continuas}
Una variable aleatoria es continua si:
\begin{enumerate}
    \item 
    \begin{enumerate}
        \item El conjunto de valores posibles se compone de todos los numeros que hay en un solo intervalo o una union excluyente de estos.
        \item Ninguno de estos valores tiene un valor de probabilidad positivo $P(x=c) = 0 \hspace{8px} \forall c \in \mathbb{R}$  
    \end{enumerate}
    \item Se dice que $X$ es una variable continua si existe una funcion $f_{X}: \mathbb{R} \to \mathbb{R}$, llamada \underline{funcion de densidad}
    de probabilidad, que satisface las siguientes condiciones:
    \begin{enumerate}
        \item $f_{X} \geq 0 \hspace{8px} \forall x \in \mathbb{R}$
        \item $\int_{-\infty}^{\infty} f_{X}(x) dx = 1$
        \item Para cualquier $a$ y $b$ tales que $-\infty < a<b< +\infty$:
        \begin{equation*}
            P(a<X<b) = \int_{a}^{b} f_{X}(x) dx
        \end{equation*}
    \end{enumerate}
\end{enumerate}

\subsubsection*{Teorema}
Sea $F_{X} (x)$ una funcion de distribucion de una V.A.C. (admite derivada), luego:
\begin{equation*}
    f_{X}(x) = \frac{dF_{X}(x)}{dx}
\end{equation*}
\textbf{OBS}: La funcion de densidad solo existe para V.A.C.

\subsection{Eventos equivalentes}
Dos eventos son equivalentes si acumulan la misma probabilidad. Para V.A.D. significa que ambos eventos tiene la misma probabilidad.

\section{Modelos continuos: distribuciones notables}
\subsection{Distribucion Uniforme}
Supongamos una V.A.C. que toma todos los valores sobre un intervalo $[a,b]$. Si $f_{X}(x)$ esta dada por:
$$f_{X}(x)= \left\{ \begin{array}{lcc}
    \frac{1}{b-a} &   si  & a<X<b \\
    \\0 &  e.o.c 
    \end{array}
\right.$$
Se denota como $X \sim \mathcal{U} (a,b)$
\subsection{Distribucion exponencial}
Una variable aleatoria tiene una distribucion exponencial de parametro $\lambda > 0$ si su funcion de densidad esta dada por:
$$f_{X}(x)= \left\{ \begin{array}{lcc}
    \lambda e^{-\lambda x} &   si  & x>0 \\
    \\0 &  e.o.c 
    \end{array}
\right.$$

Y su funcion de distribucion es:
\begin{equation*}
    F_{X}(x)=P(X \leq x) = \left\{ \begin{array}{lcc}
        0 &   si  & x<0 \\
        \\ \int_{0}^{\alpha} \lambda e^{-\lambda t} dt = 1- e^{-\lambda \alpha} & &  e.o.c 
        \end{array}
    \right.
\end{equation*}
\subsubsection*{Propiedades de la exponencial}
\begin{enumerate}
    \item (PERDIDA DE MEMORIA) Si $X \sim \mathcal{E} (\lambda)$ entonces $P(X>t+s|X>t) = P(X>s)$  $\forall \hspace{8px} t,s  \in \mathbb{R}$.
    \item Si $X$ es una V.A.C. y $P(X>t+s|X>t) = P(X>s)$  $\forall \hspace{8px} t,s \in \mathbb{R}^{+}$ entonces existe $\lambda >0 $ tal que $X \sim \mathcal{E}(\lambda)$
\end{enumerate}

\subsection{Funcion de Riesgo (para V.A.C.)}
Dada la funcion intensidad de fallas $\lambda (t)$, la funcion de distribucion es:
\begin{equation*}
    F(t)= 1-e^{-\int_{0}^{\infty} \lambda(s)ds} \hspace{16px} \text{si  } t>0
\end{equation*}

\subsection{Distribucion Gamma}
Se dice una V.A tiene distribucion Gamma de parametros $\lambda$ y $k$ si su funcion de densidad es:
\begin{equation*}
    f_{X}(x)= \frac{\lambda^k}{\Gamma(k)}x^{k-1}e^{-\lambda x} \hspace{16px} \text{si  } \{x>0\}
\end{equation*}

\subsection{Distribucion normal estandar}
La V.A. X que toma los valores $-\infty < x < +\infty $ tiene una distribucion normal estandar si su funcion de densidad es:
\begin{equation*}
    f_{X}(x) = \frac{1}{\sqrt{2\pi}} e^{\frac{-x^{2}}{2}}
\end{equation*}
Para calcular probabilidades de esta distribucion hay que mirar la tabla o integrar numericamente.

\subsection{Cuantil de una V.A}

Un cuantil $\alpha$ de $X$ es cualquier numero $x_{\alpha}$ tal que :
\begin{equation*}
    P(X<x_{\alpha}) \leq \alpha \text{  y  } P(X>x_{\alpha}) \leq 1-\alpha
\end{equation*}

\section{Funciones de variables aleatorias}
Sea $ Y = g(X)$ con X una variable aleatoria:\\
Si $X$ es una V.A.D., Y sera discreta con:
\begin{equation*}
    p_{Y}(y) = P(Y=y) = \sum_{x \in B} p_{x}(x) \hspace{16px} \text{ con } \hspace{8px} B = \{ x\in \mathbb{R}: g(x)=y \}
\end{equation*}
Y en general:
\begin{equation*}
    F_{Y}(y)= P(Y \leq y) = P(g(x) \leq y)
\end{equation*}
Y con esta ultima se calcula la probabilidad $\forall y \in \mathbb{R}$

\subsection{Simulacion}
Sabiendo la distribucion de $X$ y teniendo una variable aleatoria $U$ para generar valores al azar, sabiendo su distribucion, entonces
se busca una $F_{U}(u_{i}) = F_{X}(x_{i})$, de donde se puede despejar $x_{i}$ en funcion de $u_{i}$.
Este despeje se puede hacer mediante la \underline{INVERSA GENERALIZADA}:
\begin{equation*}
    F_{X}^{-1}(u) = min \{x \in \mathbb{R}: F_{X}(x) \leq u \} \hspace{16px} \text{con } u \in (0,1)
\end{equation*}

\subsubsection*{Teorema}
Si f es una funcion que cumple:
\begin{itemize}
    \item Ser no decreciente.
    \item $\lim_{x \to +\infty}F(x) = 1$ y $\lim_{x \to -\infty}F(x) = 0$.
    \item Continua a derecha.
\end{itemize}
$\Rightarrow X = F^{-1}(U)$ con $U \sim \mathcal{U}(0,1)$, se tiene que $X$ es una V.A. cuya funcion de de distribucion es la funcion F dada.

\section{Truncamiento}
Sea $X$ una V.A con $F_{X}(x) = P(X\leq x)$
\begin{equation*}
    F_{X|X \in A}(x) = P(X \leq x | X \in A)\\
    \hspace{60px}=\frac{P(X \leq x, X \in A)}{P(X \in A)}
\end{equation*}
Si X es continua, $f_{X}(x) = \frac{dF_{X}(x)}{dx}$
\begin{equation*}
    \Rightarrow f_{X|X \in A}(x) = \frac{d}{dx}F_{X|X \in A(x)} = \frac{f_{X}(x) \mathbbm{1} \{X \in A\}}{P(X \in A)}
\end{equation*}

\section{Vectores Aleatorios}
$\mathbb{X}  = (X_{1},X_{2},X_{3},...,X_{n})$ es un vector aleatorio de dimension $n$ si para cada $j = 1,...,n$; $X_{j}: \Omega \to \mathbb{R}$ es una
V.A.
\subsection{Funcion de distribucion de un vector aleatorio}
Sea $\mathbb{X}$ un vector aleatorio de dimension $n$, definimos la funcion de distribucion de $\mathbb{X}$ como:
\begin{equation*}
    F_{\mathbb{X}}(\bar{x}) = P(X_{1} \leq x_{1},X_{2} \leq x_{2}, X_{3} \leq x_{3},..., X_{n} \leq x_{n})
\end{equation*}

\subsection{Propiedades del vector aleatorio ($\mathbb{X} = (X,Y)$)}
\begin{enumerate}
    \item $\lim_{x,y \to \infty} F_{\mathbb{X}}(x) =1$,
    \item $ F_{\mathbb{X} (x)}$ es monotona no decreciente en cada variable.
    \item $ F_{\mathbb{X} (x)}$ es continua a derecha en cada variable.
    \item $ P((X,Y) \in (a_{1},b_{1})x(a_{2},b_{2})) = F_{\mathbb{X}(b_{1},b{2})} - F_{\mathbb{X}(b_{1},a{2})} -F_{\mathbb{X}(a_{1},b{2})} + F_{\mathbb{X}(a_{1},a{2})}$ 
\end{enumerate}

\subsection{Funcion de probabilidad de vectores aleatorios discretos (probabilidad conjunta)}
Sean $X$ e $Y$ dos V.A.D definidas en el espacio muestral $\Omega$ de un experimento.
La funcion de probabilidad conjunta se define para cada par de numeros $(x,y)$ como:
\begin{equation*}
    p_{X,Y}(x,y) = P(X = x, Y = y)
\end{equation*}
Debe cumplirse que:
\begin{enumerate}
    \item $ p_{X,Y}(x,y) \geq 0 $
    \item $ \sum_{x} \sum_{y} p_{X,Y}(x,y) = 1 $
\end{enumerate}

\subsubsection{Funciones de probabilidad marginales y de conjuntos}
Para el caso de las variables aleatorias recien mencionadas, sus funciones de probabilidad
marginales estan dadas por:
\begin{equation*}
    p_{X}(x) = \sum_{y} p_{X,Y}(x,y)
\end{equation*}
\begin{equation*}
    p_{Y}(y) = \sum_{x} p_{X,Y}(x,y)
\end{equation*}
Para el caso de cualquier conjunto A compuesto por pares de valores $(x,y)$ entonces:
\begin{equation*}
    P((X,Y) \in A) = \sum_{(x,y) \in A}\sum  p_{X,Y}(x,y)
\end{equation*} 
\subsection{Funcion de densidad de un vector aleatorio continuo}
Sean $X$ e $Y$ V.A.C una funcion de denisidad de probabilidad conjunta $f_{X,Y}(x,y)$ de 
estas dos variables es una funcion que satisface:
\begin{enumerate}
    \item $f_{X,Y}(x,y) \geq 0$
    \item $ \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} f_{X,Y}(x,y) dxdy = 1 $
\end{enumerate}
\subsubsection{Funciones de densidad marginales}
Para calcular las funciones de densidad marginales de X e Y:
\begin{enumerate}
    \item $f_{X}(x) = \int_{-\infty}^{\infty} f_{X,Y}(x,y) dy$
    \item $f_{Y}(y) = \int_{-\infty}^{\infty} f_{X,Y}(x,y) dx$
\end{enumerate}

\subsection{Independecia de vectores aleatorios}
Sea $(X,Y)$ un vector aleatorio, las variables aleatorias $X$ e $Y$ son independientes
si y solo si:
\begin{equation*}
    P((X \in A) \cap (Y \in B)) = P(X \in A) \cdot P(Y \in B) \hspace*{8px} \forall A,B 
\end{equation*}
\subsubsection{Propiedades de la independencia de vectores aleatorios}
\begin{enumerate}
    \item Se dice que $X_{1}...X_{n}$ son V.A independientes sii 
    \begin{equation*}
        F_{X_{1}...X_{n}}(x_{1},...,x_{n}) = F_{X_{1}}(x_{1}) \cdot ... \cdot F_{X_{n}(x_{n})}
    \end{equation*}
    \item Se dice que las V.A discretas $X_{1},...,X_{n}$ independientes sii 
    \begin{equation*}
        p_{X_{1},...,X_{n}} (x_{1},...,x_{n}) = p_{X_{1}}(x_{1}) \cdot ... \cdot p_{X_{n}}(x_{n})
    \end{equation*}
    \item Se dice que las V.A continuas $X_{1},...,X_{n}$ son independientes sii 
    \begin{equation*}
        f_{X_{1},...,X_{n}} (x_{1},...,x_{n}) = f_{X_{1}}(x_{1}) \cdot ... \cdot f_{X_{n}}(x_{n})
    \end{equation*}
\end{enumerate}

\section{Momentos}
\subsection{Esperanza}
Es el promedio ponderado de los valores que puede tomar una V.A. ("centro de masa")
Sea $X$ una V.A.D con funcion de probabilidad $p_{X}(x)$, el valor esperado (o media) de X es:
\begin{enumerate}
    \item Para discretas:
    \begin{equation*}
        E(X) = \sum_{x \in R_{x}} x \cdot p_{X}(x)
    \end{equation*}
    \item Para continuas:
    \begin{equation*}
        E(X) = \int_{-\infty}^{\infty} x \cdot f_{X}(x)dx
    \end{equation*}
\end{enumerate}

\subsubsection{Propiedades}
\begin{enumerate}
    \item El valor de la esperanza de cualquier funcion $h(x)$ (una V.A.) se calcula como:
    \begin{enumerate}
        \item Para discretas:
        \begin{equation*}
            E(h(x)) = \sum_{x \in R_{x}} h(x) \cdot p_{x}(x)
        \end{equation*}
        \item Para continuas:
        \begin{equation*}
            E(h(x)) = \int_{-\infty}^{\infty}  h(x) \cdot f_{x}(x)
        \end{equation*}
    \end{enumerate}
    \item Sea $X$ una V.A. con E(X) = $\mu$ si $h(x) = aX+b \rightarrow E(h(X)) = a\mu+b$
\end{enumerate}
\subsubsection{CASO GENERAL}
Sea $X$ una V.A. con funcion de distribucion $F_{X}(x) = P(X\geq x)$ si $h(X)$ es una funcion 
cualquiera de $X$, si definimos A como el conjunto de atomos (valores de $X$ que concentren masa positiva), entonces:
\begin{equation*}
    E[h(X)] = \sum_{x \in A} h(x) \cdot P(X = x) + \int_{\mathbb{R} / A} h(x) \cdot F'_{X}(x)dx
\end{equation*}
\subsection{Esperanza condicional}
\begin{equation*}
    E[X|X \in A] = \frac{E[X \mathbbm{1}\{X \in A\}]}{P(X \in A)}
\end{equation*}
Si despejo, y pienso en una particion tenemos:
\begin{equation*}
    E(X) = E[X|X \in A] \cdot P(X \in A) +  E[X|X \in \bar{A}] \cdot P(X \in \bar{A})
\end{equation*}
\subsubsection{Propiedad}
Otra manera para calcular la esperanza que puede ser util:
\begin{equation*}
    E(X) = \int_{0}^{\infty}(1-F_{X}(x))dx - \int_{-\infty}^{0}F_{X}(x)dx
\end{equation*}
\subsection{Varianza}
Sea $X$ una V.A, definimos la varianza $X$ como:
\begin{equation*}
    Var(X) = E[(X-E(X))^2]
\end{equation*}
\subsubsection{Propiedad}
\begin{equation*}
    Var(X) = E[(X-E(X))^2] = E[X^2 - 2XE(X)+ E(X)]
\end{equation*}
Si $E(X)= \mu$
\begin{equation*}
    \rightarrow Var(X) = E(X^2)-2\mu E(X) + \mu^2 = E(X^2)-\mu^2 = E(X^2)-E(X)^2
\end{equation*}
\subsubsection{Desvio estandar}
Se define como la raiz cuadrada de la varianza de una V.A.:
\begin{equation*}
    \sigma_{x} = \sqrt{Var(X)}
\end{equation*}
\subsubsection{Mediana}
Es el valor de $X$ que acumula una probabilidad de 0.5 (es el cuantil 0.5) : $X / F_{X}(x) = 0.5$
\subsubsection{Moda}
Es el valor de $X$ con mayor probabilidad.
\subsection{Esperanza de una funcion de un vector aleatorio}
La esperanza de una funcion $h(X,Y)$ esta dada por:
\begin{enumerate}
    \item Si (X,Y) es un vector aleatorio discreto:
    \begin{equation*}
        E(h(X,Y)) = \sum_{x} \sum_{y} h(x,y) p_{X,Y}(x,y)
    \end{equation*}
    \item Si (X,Y) es un vector aleatorio continuo:
    \begin{equation*}
        E(h(X,Y)) = \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} h(x,y) f_{X,Y}(x,y) dxdy
    \end{equation*}
\end{enumerate}
\subsubsection{Propiedades de Orden}
Sea $X = (X_{1},...,X_{n})$ un vector aleatorio, $ g: \mathbb{R}^{k} \rightarrow \mathbb{R}$ una funcion, tenemos que:
\begin{enumerate}
    \item Si $X>0 \rightarrow E(X)>0$
    \item Si $g(x)>0 \rightarrow E(g(X))>0$
    \item Sea $ h(x)>g(x) \rightarrow E(h(X))> E(g(X)) $
    \item $E(|X|) \geq E(X)$
    \item $E(|XY|) \leq \sqrt{E(X^{2})E(Y^{2})} $
\end{enumerate}
\subsubsection{Propiedades importantes}
\begin{enumerate}
    \item \begin{equation*}
        E[\sum_{i=1}^{n}a_{i}X_{i}] = \sum_{i=1}^{n}a_{i}E(X_{i})
    \end{equation*}
    \item Si $X_{1},...,X_{n}$ son independientes entonces: \begin{equation*}
        E(\prod_{i=1}^{n}X_{i}) = \prod_{i=1}^{n}E(X_{i})
    \end{equation*}
\end{enumerate}
\subsection{Covarinza}
Sean $X$ e $Y$ dos V.A.:
\begin{equation*}
    Cov(X,Y) = E[(X-E(X))(Y-E(Y))]
\end{equation*}
\subsubsection{Propiedades de la Covarinza}
\begin{enumerate}
    \item $Cov(X,Y) = E(X \cdot Y) - E(X)E(Y)$
    \item Si $X$ e $Y$ son independientes entonces $E(X \cdot Y) = E(X)E(Y) \rightarrow Cov(X,Y)=0$
    \item $Cov(a+bX,c+dY) = b \cdot d \cdot Cov(X,Y)$ 
    \item $Cov(X+Y,Z) = Cov(X,Z)+Cov(Y,Z)$
    \item $Var(X+Y) = Var(x) + Var(Y) + 2Cov(X,Y)$
\end{enumerate}
\subsubsection{Coeficiente de correlacion}
Entre las V.A $X$ e $Y$ esta dado por:
\begin{equation*}
    \rho_{XY} = \frac{Cov(X,Y)}{\sqrt{Var(X)Var(Y)}}
\end{equation*}
$\rightarrow -1 \leq \rho_{XY} \leq 1$ \\
Propiedad: \\
\begin{equation*}
    |\rho_{XY}| = 1 \leftrightarrow P(aX+b =Y) =1 
\end{equation*}
\section{Prediccion}
Sea Y una V.A., $\mathbb{X} = (X_{1},...,X_{n})$ un vector aleatorio, existira alguna funcion $g(\mathbb{X})$ que nos 
sirva para predecir a $Y$. Para encontrar dicha funcion se calcula el error cuadratico medio:
\begin{equation*}
    ECM = E[(Y-g(\mathbb{X}))^{2}]
\end{equation*}
\subsection{Los mejores predictores}
\begin{enumerate}
    \item Constante: $E(X)$
    \item Lineal: Recta de regresion de $Y$ basada en $X$ 
    \begin{equation*}
        g(X) = \hat{Y} = \frac{Cov(X,Y)}{Var(X)}(X-E(X))+E(Y)
    \end{equation*}
\end{enumerate}
\section{Desigualdades}
\subsection{Desigualdad de Markov}
Sea $h: \mathbb{R} \rightarrow \mathbb{R}^{+}$ tal que h es par, y restringida a $R^{+}$ es creciente, y sea $X$ una V.A, tal que $E(h(X))$ existe,
entonces $\forall t \in \mathbb{R}$,
\begin{equation*}
    P(|X| \geq t) \leq \frac{E[h(X)]}{h(t)}
\end{equation*}
Si ademas $X$ es no negativa, $\forall a > 0$
\begin{equation*}
    P(X \geq a) \leq \frac{E(X)}{a}
\end{equation*}
\subsection{Desigualdad de Tchevychev}
Sea $X$ una V.A. con varianza finita, $\forall k > 0$:
\begin{equation*}
    P(|X - E(X)| \geq k) \leq \frac{Var(X)}{k^{2}}
\end{equation*}
(desigualdad de Markov si $Y = X-E(X)$ y $h(t) = t^{2}$)
\section{Funcion de variable aleatoria (cambio de variable)}
Sea $X$ una variable aleatoria, sea $Y=g(x)$ una funcion de la variable $X$,
buscamos encontrar la distribucion de la variable $Y$.
\subsection{Metodo de eventos equivalentes}
\begin{equation*}
    F_{Y}(y)= P(Y \leq y) = P(g(X) \leq y)
\end{equation*}
\subsection{Metodo del Jacobiano (para vectores aleatorios)}
Suponga que $Y_{1}$ e $Y_{2}$ con V.A. continuas con funcion de densidad conjunta
$f_{Y_{1},Y_{2}}(y_{1},y_{2})$ y que para todo $(y_{1},y_{2})$ tal que 
$f_{Y_{1},Y_{2}}(y_{1},y_{2}) > 0$, $u_{1} = h_{1}(y_{1},y_{2})$, $u_2=h_{2}(y_{1},y_{2})$
es una transformacion 1 a 1 de $(y_{1},y_{2})$ y $(u_{1},u_{2})$ con inversa 
$y_{1}=h_{1}^{-1}(u_{1},u_{2})$, $y_{2}=h_{2}^{-1}(u_{1},u_{2})$. Si las inversas
tienen derivadas parciales continuas respecto de $u_{1}$ y $u_{2}$ con jacobiano $J$,
entonces:
\begin{equation*}
    f_{U_{1},U_{2}}(u_{1},u_{2}) = \frac{f_{Y_{1},Y_{2}}(y_{1},y_{2})}{|J|} \bigg\rvert_{h_{1}^{-1}, h_{2}^{-1}}
\end{equation*}
\section{Variables aleatorias condicionadas}
Sea $X$ e $Y$ variables aleatorias discretas con $p_{X}(x)>0$, la funcion 
de probabilidad de $Y$ dada que $X=x$ es:
\begin{eqnarray*}
    p_{Y|X=x}(y) = P(Y=y|X=x) = \frac{P(X=x,Y=y)}{P(X=x)} \\
    \rightarrow p_{Y|X=x}(y)=\frac{p_{X,Y}(x,y)}{p_{X}(x)}
\end{eqnarray*}
Se define como $p_{Y|X=x}(y)=0$ cuando $p_{X}(x)=0$\\
Recordar:
\begin{eqnarray*}
    p_{X,Y}(x,y) = p_{Y|X=x}(y)p_{X}(x)\\
    p_{X,Y}(x,y) = p_{X|Y=y}(x)p_{Y}(y) 
\end{eqnarray*}
Sea $(X,Y)$ un vector aleatorio continuo con densidad conjunta $f_{X,Y}(x,y)$ y densidad marginal $f_{X}(x)$ 
, entonces para cualquier valor de $X$ con el cual $f_{X}(x)$, la funcion de densidad de la variable condicionada $Y$ dada $X=x$ es:
\begin{equation*}
    f_{Y|X=x}(y) = \frac{f_{X,Y}(x,y)}{f_{X}(x)}
\end{equation*}
Si $f_{X}(x) = 0$ entonces se define como $f_{Y|X=x}=0$
\subsection{Propiedades}
\begin{enumerate}
    \item Sea $X$ e $Y$ V.A. discretas tales que $p_{Y|X=x}(y)=p_{y}(y) \hspace{8px} \forall x \in \mathbb{R}$\\
    $\rightarrow X$ e $Y$ son independientes.
    \item $f_{X,Y}(x,y)=f_{Y|X=x}(y) \cdot f_{X}(x)$
\end{enumerate}
\section{Mezcla de variables aleatorias: Bayes para la mezcla}
Sea $M$ una V.A.D. con soporte finito y $X$ una V.A.C., de manera que conozco la funcion de probabilidad de $M$
y la funcion de densidad de las variables aleatorias $X|M=m, \hspace{8px} \forall m \in R_{M}$.
La funcion de probabilidad de $M$ dado que $X=x$ sera:
\begin{equation*}
    p_{M|X=x}(m) = \frac{f_{X|M=m}(x) \cdot P(M=m) }{\sum_{i \in R_{M}}f_{X|M=i}(x) \cdot P(M=i)}
\end{equation*}
\section{Esperanza condicional}
Si $Y|X=x$ es una V.A.D.
\begin{equation*}
    \rightarrow E[Y|X=x] = \sum_{y \in R_{Y|X=x}}y \cdot p_{Y|X=x}(y)
\end{equation*}
Si $Y|X=x$ es una V.A.C.
\begin{equation*}
    \rightarrow E[Y|X=x] = \int_{-\infty}^{\infty} y \cdot f_{Y|X=x}(y)
\end{equation*}
 Ambas son funcion de $x$ y se las llama \color{orange} Funcion de Regresion ($\phi (x)$)\color{black}\\
 De aca desprende la definicion de Esperanza Condicional:\\
 Si llamamos $\phi (x) = E[Y|X=x]$ a la esperanza de la variable condicionada $Y$ dado que $X = x$, luego 
 $\phi: Sop(X)\rightarrow \mathbb{R}$ \\
 Vamos a definir una variable aleatoria llamada \color{purple} Esperanza Condicional \color{black} de $Y$ dada $X$, denotada por $E[Y|X]$,
 como $\phi (X)= E[Y|X]$ (cuidado!!!! es una V.A, no una esperanza)\\
 Otra definicion:\\
 La V.A. Esperanza Condicional de $Y$ dada $X$ se define como $\phi = E[Y|X]$, con $\phi$ una funcion medible tal que 
 $E[(Y-\phi(x))\cdot t(X)] = 0$ para toda funcion $t$ medible $t:Sop(x)\rightarrow \mathbb{R}$ tal 
 que $Y \cdot t(X)$ tiene esperanza finita.
 Definimos $\phi(x) = E[Y|X=x]$
 \subsection{Propiedades}
 \begin{enumerate}
     \item $E[E[Y|X]] = E[Y]$
     \item Sea $X$ e $Y$ variables aleatorias, $s$ y $r$ funciones medibles tales que las variables aleatorias $r(X) \cdot s(Y)$; $r(X)$ y $s(Y)$ tiene esperanza finita, entonces 
     \begin{equation*}
         E[r(X) \cdot s(Y)|X] = r(X) E [s(Y)|X]
     \end{equation*}
     \item Sean $Y_{1}$ e $Y_{2}$ V.A con esperanza finita
     \begin{equation*}
         E[aY_{1}+bY_{2}|X] = aE[Y_{1}|X] + bE[Y_{2}|X]
     \end{equation*}
     \item $E[Y|X] = E[Y]$ si $X$ e $Y$ son independientes
     \item $E[r(X)|X] = r(X)$
 \end{enumerate} 

 OBS: La esperanza condicional es de $Y$ dado $X$ es la funcion de la V.A. $X$ que mejor predice a $Y$.
\section{Varianza Condicional}
Sean $X$ e $Y$ variables aleatorias con $Var(Y)$ finita, la varianza de $Y|X=x$ sera:
\begin{equation*}
    Var(Y|X=x)=E[(Y-E(Y|X=x))^{2}|X=x]
\end{equation*}
Llamaremos $T(x)=Var(Y|X=x)$, $T: Sop(X) \rightarrow \mathbb{R}$ llamaremos varianza condicional de $Y$ dada $X$ a la V.A:
\begin{equation*}
    T(X) = Var(Y|X) = E[(Y-E(Y|X))^{2}|X]
\end{equation*}
Desarrollando el cuadrado y aplicando propiedades de esperanza condicional:
\begin{equation*}
    Var(Y|X) = E[Y^{2}|X] - E[Y|X]^{2}
\end{equation*}
\subsection{Propiedad (Pitagoras)}
\begin{equation*}
    Var(Y) = E[Var(Y|X)] + Var(E[Y|X])
\end{equation*}
\section{Proceso de Bernoulli}
\subsection{Condiciones}
\begin{enumerate}
    \item Dicotomia (Sucede un evento, o no sucede)
    \item Probabilidad constante
    \item Los experimentos son independientes
\end{enumerate}
Entonces tendremos una V.A. $X \backsim Ber(p)$ y $X_{1},X_{2},...$ una sucesion de V.A.
tales que \\ $X_{1},X_{2},...\backsim X$
\subsection{Variables definibles}
Las variables definibles en este tipo de proceso son:
\begin{enumerate}
    \item $Y$:'Cantidad de exitos en $n$ ensayos de Bernoulli', donde $Y \backsim B(n,p)$
    \item $W$:'Cantidad de ensayos hasta lograr $k$ exitos', donde $W \backsim Pas(k,p)$
    \item $N$:'Cantidad de ensayos hasta el $1^{o}$ exito', donde $N \backsim \mathcal{G}(p)$
\end{enumerate}
\section{Proceso de Poisson (puntual)}
Un proceso puntual aleatorio es un conjunto enumerable de puntos aleatorios ubicado sobre la recta real.
En la mayoria de las aplicaciones un punto de un proceso puntual es el instante en que ocurre algun 
evento, motivo por el cual los puntos tambien se llaman eventos o arribos.\\
Llamemos $N(t)$ al numero d eventos durante un intervalo especifico $[0,t]$
\begin{enumerate}
    \item El numero de eventos durante intervalos de tiempo no superpuestos son variables aleatorias independientes ($N_{1}$ y $N_{2}$ son independientes).
    \item La probabilidad de cada evento particular es la misma para todos los intervalos de longitud $t$, independientemente de la ubicacion de cada intervalo y de la historia pasada del sistema ($N_{1}$ y $N_{2}$ tienen la misma distribucion de probabilidades).
    \item La probabilidad de obtener 2 o mas eventos en un intervalo lo suficientemente chico es despreciable.
\end{enumerate}
La variable $N(t)$ toma los valores posibles ${0,1,2,...} = \mathbb{N} \cup {0}$ y su funcion de probabilidad esta dada por
\begin{equation*}
    p_{N}(n) = \frac{(\lambda t)^{n}}{n!} e^{-\lambda t}
\end{equation*}
donde $\lambda > 0$. Entonces $N(t)$ tiene distribucion de Poisson de parametro $\mu = \lambda t$
\subsection{Variables definibles}
En un Proceso de Poisson de intensidad o tasa de ocurrencia $\lambda$ (PP$(\lambda)$):
\begin{enumerate}
    \item $N(t)$: 'Cantidad de eventos en el intervalo de longitud $t$', donde $N(t) \backsim Poi(\lambda t)$
    \item $T$: 'Tiempo entre dos eventos consecutivos', donde $T \backsim Exp(\lambda)$
    \item $G$: 'Tiempor hasta el $k$-esimo evento de Poisson', donde $G \backsim \Gamma(k,\lambda)$
\end{enumerate}
\subsection{Propiedades}
\subsubsection{Adelgazamiento}
Sea $\{N(t);t>0\}$ un proceso de Poisson de tasa $\lambda$. Cada vez que ocurre un evento se lo clasifica como de tipo $I$ o de tipo 
$II$. Mas aun se clasifica como de tipo $I$ con probabilidad $p$ o como de tipo $II$ con probabilidad $(1-p)$, independientemente de todos los demas arribos.
Sean $N_{I}(t)$ y $N_{II}(t)$ la cantidad de arribos de tipo $I$ y $II$ que ocurren en $[0,t]$. Es claro que $N(t) = N_{I}(t) + N_{II}(t)$. Estos dos nuevos procesos son independientes.
\subsubsection{Superposicion de procesos de Poisson}
Sean $\{N_{1}(t),t\geq0\}$ y $\{N_{2}(t),t\geq0\}$ procesos de Poisson independientes de tasas $\lambda_{1}$ y $\lambda_{2}$ respectivamente. Entonces $N(t)=N_{1}(t)+N_{2}(t)$ 
define un proceso de Poisson de tasa $\lambda = \lambda_{1} + \lambda_{2}$.
\subsection{Teorema}
Bajo la condicion de que ocurrieron exactamente $n$ arribos en el intervalo $[0,t]$ los tiempos de los $n$ arribos $S_{1},S_{2},...,S_{n}$, considerados como variables aleatorias desordenadas, son independientes y estan distribuidas
uniformemente spbre $[0,t]$
\section{Distribucion Normal}
La V.A. X que toma todos los valores reales $-\infty < x< \infty$ tiene una distribucion normal de parametros $\mu \in \mathbb{R} $ y $\sigma^{2}>0$
si su funcion de densidad es de la forma:
\begin{equation*}
    f_{X}(x) = \frac{1}{\sqrt{2\pi\sigma^{2}}}e^{\frac{-1}{2\sigma^{2}}(x-\mu)^{2}}
\end{equation*}
$\rightarrow X \backsim \mathcal{N}(\mu,\sigma^{2})$\\
Con $E[X]=\mu$ y $Var(X)=\sigma^{2}$
\subsection{Metodo de calculo de probabilidades}
Sabemos que $Z \backsim \mathcal{N}(0,1) \rightarrow P(Z \leq z) = \Phi(z)$\\
Si $X \backsim \mathcal{N}(\mu,\sigma^{2})$ busco una transformacion.\\
Se propone $Z = \frac{X-\mu}{\sigma}$ de manera tal que si $X \backsim \mathcal{N}(\mu,\sigma^{2}) \rightarrow Z \backsim \mathcal{N}(0,1)$ 
\subsubsection{Propiedad}
Si $X \backsim \mathcal{N}(\mu,\sigma^{2})$ entonces:
\begin{eqnarray*}
    P(\mu - \sigma < X < \mu + \sigma) = P(-1<Z<1) &=& \Phi(1)- \Phi(-1) = \Phi(1)- (1- \Phi(1)) = 2\Phi(1) -1 \\
    P(\mu - 2\sigma < X < \mu + 2\sigma) = 2\Phi(2)-1 \\
    P(\mu - 3\sigma < X < \mu + 3\sigma) = 2\Phi(2)-1
\end{eqnarray*}
\section{Distribucion Normal Multivariada}
Se dice que el vector aleatorio $X=(x_{1},...,X_{p})$ tiene distribucion normal multivariada de dimension $p$,
de parametros $\mu \in \mathbb{R}^{p}$ y $\sum \in \mathbb{R}^{p\times p}$ (simetrica y definida positiva)
$X \backsim \mathcal{N}_{p}(\mu, \Sigma)$, si su funcion de densidad esta dada por:
\begin{equation*}
    f_{X}(x) = \frac{1}{(2\pi)^{p/2}|\Sigma|^{1/2}}\cdot exp\{\frac{1}{2}(x-\mu)^{T}\Sigma^{-1}(x-\mu)\}
\end{equation*}
Con $X$ y $x$ vectores en $\mathbb{R}^{p}$.\\
Definiendo $\mu$ y $\Sigma$ (Matriz de Covarinzas) como:
\begin{equation*}
    \mu = \begin{bmatrix}
        E(X_{1})\\
        E(X_{2})\\
        \vdots\\
        E(X_{p})\\
    \end{bmatrix} 
    \Sigma = \begin{bmatrix}
        Var(X_{1}) = Cov(X_{1},X_{1}) & Cov(X_{1},X_{2}) & \cdots & Cov(X_{1},X_{p}))\\
        \vdots & \cdots & \cdots & \vdots \\
        Cov(X_{p},X_{1}) & \cdots & \cdots &  Cov(X_{p},X_{p}) = Var(X_{p})
    \end{bmatrix}
\end{equation*}
\subsection{Propiedades}
\begin{enumerate}
    \item Si $X \backsim \mathcal{N}_{p}(0,diag(\lambda_{1},...,\lambda_{p}))$ entonces $X_{1},...,X_{p}$ son independientes y $X_{i} \backsim \mathcal{N}(0,\lambda_{i})$.
    \item Si $X \backsim \mathcal{N}_{p}(\mu,\Sigma)$ y $A \in \mathbb{R}^{p \times p}$ no singular entonces $AX + b \backsim \mathcal{N}_{p}(A\mu+b,A\Sigma A^{T})$.
\end{enumerate}
\subsection{Teorema}
Sean $X_{1},...,X_{n}$ V.A. aleatorias independientes con $X_{i} \backsim \mathcal{N}(\mu_{i}, \sigma^{2}_{i})$, $i=1,...,n$ y sea $Y = \sum_{i=1}^n a_{i}X_{i}$
,entonces $Y$ tendra una distribucion normal de parametros $\mu_{Y}  = \sum_{i=1}^{n} a_{i}\mu_{i}$ y 
$\sigma_{Y}^{2} = \Sigma_{i=1}^{n}a_{i}^{2}\sigma_{i}^{2}$
\section{Teoremas Limites}
\subsection{Ley de los grandes numeros}
Si se tiene una sucesion de V.A. $(X_{n})n \geq 1$ independientes con $E[X_{i}] = \mu < \infty$ y $Var(X_{i}) = \sigma^{2} < \infty, \bar{X_{n}} = \frac{1}{n}\sum_{i=1}^{n}X_{i}$ entonces $\bar{X} \rightarrow \mu$.\\
\subsection{Ley debil de los grandes numeros}
\begin{equation*}
    P(|\bar{X_{n}} - \mu| > \varepsilon) \rightarrow_{n \rightarrow \infty} 0
\end{equation*}
Entonces $E(\bar{X_{n}}) = \mu$, $Var(\bar{X_{n}}) = \frac{\sigma^{2}}{n}$
\section{Teorema Central del Limite (TCL)}
Sean $(X_{n})_{n \geq 1}$ una sucesion de V.A. indep. e identicamente distribuidas con $E(X_{i}) = \mu < \infty$ y $Var(X_{i}) = \sigma^{2} < \infty$, $i=1,...,n$, entonces (bajo ciertas condiciones generales):
\begin{equation*}
    \frac{\sum_{i=1}^{n}X_{i} - n\cdot\mu}{\sqrt{n\cdot \sigma^{2}}} \rightarrow Z \backsim \mathcal{N}(0,1)
\end{equation*}
Es decir:
\begin{equation*}
    P( \frac{\sum_{i=1}^{n}X_{i} - n\cdot\mu}{\sqrt{n\cdot \sigma^{2}}}\leq t) \rightarrow_{n\rightarrow \infty} \Phi(t)
\end{equation*}
OBS: Saber siempre que esto es una aproximacion!
\section{Resumen de sumas de V.A idd}
\begin{enumerate}
    \item Si $X_{1},...,X_{n} \backsim Ber(p) \rightarrow \sum_{i=1}^{n} X_{i} \backsim  B(n,p)$
    \item Si $X_{1},...,X_{n} \backsim G(p) \rightarrow \sum_{i=1}^{n} X_{i} \backsim  Pas(n,p)$
    \item Si $X_{1},...,X_{n} \backsim Exp(\lambda) \rightarrow \sum_{i=1}^{n} X_{i} \backsim  \Gamma(n,\lambda)$
    \item Si $X_{1},...,X_{n} \backsim \author{}(p) \rightarrow \sum_{i=1}^{n} X_{i} \backsim  B(n,p)$
\end{enumerate}
\section{Estadistica}
Inferencia: Construir un modelo sobre la base de datos experimentales y extraer conclusiones.\\
Totalidad de los resultados experimentales posibles$\rightarrow$ POBLACION. \\ 
Conjunto de datos que se obtiene de realizar el experimento una cierta cantidad de veces $\rightarrow$ MUESTRA. 
\subsection{Concepto de muestra}
Variable aleatoria $X$, definida sobre $(\Omega,\mathcal{A},P)$ con distribucion $F_{X}(x) = P(X \leq x)$ que se desconoce (al menos parcialmente)\\
$X \rightarrow $ "Observable" de experimento aleatorio.\\
Quiero saber como se comporta la POBLACION.\\
Muestra aleatoria: Sucesion de variables independientes $X_{1},X_{2},...$ todas iid a $X$.\\
Tendremos que $F_{X_{1},...,X_{n}}(x_{1},...,x_{n}) = P(X_{1} \leq x_{1},...,X_{n} \leq x_{n}) = \prod_{i=1}^{n} F_{X}(x_{i}), \forall n \in \mathbb{N}$\\
Notacion:\\
$\underline{X} = (X_{1},...,X_{n})$ muestra aleatoria de tamaño n con $X_{1},...,X_{n}$.\\
$\underline{x} = (x_{1},...,x_{n})$ $n$ observaciones obtenidas al realizar $n$ repeticiones independientes de tamaño $n$.
\section{Modelos parametricos}
La distribucion de $X$ pertence a una familia de distribuciones $\mathcal{F}$ que dependen de un parametro desconocido.\\
\subsection{Familia parametrica de distribuciones}
$\mathcal{F} = \{ F_{\theta}(x): \theta \in \Theta \}$ sera una familia de ditribuciones de probabilidad parametrizadas por un subconjunto
no vacio $\Theta \in \mathbb{R}^{p}$ llamada espacio parametrico.\\
Correspondecia uno a uno :
\begin{equation*}
    F_{\theta_{1}}(x) \neq F_{\theta_{2}}(x) \leftrightarrow \theta_{1} \neq \theta_{2}
\end{equation*}
\subsection{Ejemplos de familias parametricas}
\begin{enumerate}
    \item $X \backsim Ber(p) \rightarrow f_{p}(x) = p^{x}(1-p)^{1-x}, 0 < p < 1$ con $p \in \Theta = (0,1)$
    \item $T \backsim Exp(\lambda) \rightarrow f_{\lambda}(t) = \lambda e ^{-\lambda t}, \lambda > 0 $
    \item $Y \backsim \mathcal{N}(\mu, \sigma^{2}) \rightarrow f_{\mu,\sigma^{2}} (x) = \frac{1}{2 \pi \sigma^{2}} e^{-\frac{1}{2 \sigma ^{2}}(x-\mu)^{2}}, \mu \in \mathbb{R}, \sigma^{2} > 0  $
\end{enumerate}
\subsection{Familia Regular}
\begin{enumerate}
    \item El soporte de $f_{\theta}(x)$ no depende de $\theta$.
    \item $f_{\theta}$ es derivable con respecto a $\theta \hspace{8px} \forall x$.
    \item El conjunto parametrico $\Theta \in \mathbb{R}^{p}$ es discreto. 
\end{enumerate}
\subsection{Familias exponenciales}
Se dice que una familia de distribuciones (continuas o discretas) en $\mathbb{R}^{q}$ con distribucion $F_{\theta}$
, $\theta \in \Theta \subset \mathbb{R}^{k} $ es una familia exponencial a $k$ parametro, si una funcion de densidad (o probabilidad) 
se puede escribir como:
\begin{equation*}
    f_{\theta}(x) = A(\theta) e^{\sum_{i=1}^{k}C_{i}(\theta)r_{i}(x)} \cdot h(x)
\end{equation*}
Donde:
\begin{eqnarray*}
    C(\theta) \hspace{16px} \Theta \rightarrow \mathbb{R}\\
    A(\theta) \hspace{16px} \Theta \rightarrow \mathbb{R}^{+}\\
    r_{i}(x) \hspace{16px} \mathbb{R}^{q} \rightarrow \mathbb{R}\\
    h(x) \hspace{16px} \mathbb{R}^{q} \rightarrow \mathbb{R}^{+}\\
\end{eqnarray*}
\section{Funcion de Verosimilitud}
Es la funcion conjunta (de densidad o probabilidad) visita como funcion del parametro desconocido $\theta$:
\begin{eqnarray*}
    \mathcal{L}(\theta) = \prod_{i=1}^{n} f_{\theta} (x_{i}) \text{ si } \underline{x} \text{ es continuo.}\\
    \mathcal{L}(\theta) = \prod_{i=1}^{n} p_{\theta} (x_{i}) \text{ si } \underline{x} \text{ es discreto.}\\  
\end{eqnarray*}
\section{Estadistico}
Un estadistico es cualquier funcion medible $T_{n} = T(\underline{X})$ con valores en un espacio eucliedeo de dimension finita.\\
Dada una m.a. $\underline{X}$, un estadistico es una funcion de la m.a. que evaluada en los valores observados, debe porder resultar en un valor
numerico. Esta no puede depender de los parametros desconocidos. El estadistico es una funcion de la m.a. $\underline{X} \rightarrow$ es una V.A.
\subsection{Estadisticos Suficientes}
Sea $\underline{X} = (X_{1},...,X_{n})$ un vector aleatorio de dimension $n$ cuya distribucion es $F_{\theta}(\underline{x}), \hspace{8px} \theta \in \Theta$ se dice que un 
estadistico $T = r(\underline{X})$ es suficiente para $\theta$ si la distribucion de $\underline{X}$ condicionada a que $T=t$ es independiente de $\theta \hspace{8px} \forall \hspace{8px} t$.\\
Esto significa que si conozco a $T$ y la distribucion de $\underline{X}|T=t$, entonces puedo reconstruir una muestra con la misma distribucion que la muestra original.
\subsection{Teorema de Factorizacion}
Sea $\underline{X}$ un vector aleatorio con funcion de densidad (o probabilidad) conjunta $f_{\theta}(\underline{x}), \hspace{8px} \theta \in \Theta$ entonces el estadistico 
$T = r(\underline{X})$ es suficiente para $\theta$ si y solo si existen dos funciones $h$ y $g$ tales que:
\begin{equation*}
    f_{\theta}(x) = g(r(\underline{x}),\theta) \cdot h(\underline{x})
\end{equation*}
\subsection{Teorema}
Una familia exponencial a $k$ parametros tiene como estadistico suficiente para $\theta \in \mathbb{R}^{k}$ al vector:
\begin{equation*}
    T = (r_{1}(\underline{X}),...,r_{k}(\underline{X}))
\end{equation*}
Si $X_{1},...,X_{n}$ es una m.a. de una distribucion perteneciente a una familia exponencial a $k$ parametros entonces al vector aleatorio $\underline{X}$ tambien tiene una distribucion perteneciente a una familia exponencial a $k$ parametros, y el estadistico suficiente para $\theta$ basado en la m.a. sera:
\begin{equation*}
    T = (\sum_{i=1}^{n}r_{1}(X_{1}),...,\sum_{i=1}^{n}r_{k}(X_{1}))
\end{equation*} 
\section{Estimadores}
\begin{enumerate}
    \item Es un estadistico cuyos valores se consideran medidas experimentales de un parametro desconocido.
    \item Un estimador es una funcion de la muestra (estadistico) que provee un valor aproximado de un parametro o caracteristica desconocida.
\end{enumerate} 
\subsection{Metodo de maxima verosimilitud}
Es un metodo para construir estimadores puntuales. Se basa en que, en los experimentos aleatorios, los resultados observados deben tener alta probabilidad de ocurrir.\\
Diremos que $\hat{\theta}(\underline{X})$ es un estimador de maxima verosimilitud de $\theta$ si se cumple que:
\begin{equation*}
    f_{\hat{\theta}}(\underline{X}) = max_{\theta}f_{\theta}(\underline{x})
\end{equation*}
Es decir, buscamos el valor de $\theta$ que maximiza la funcion de verosimilitud.
\begin{equation*}
    \hat{\theta} = argmax_{\theta} \mathcal{L}(\theta)
\end{equation*}
A partir de la funcion de verosimilitud $\mathcal{L}(\theta)$ vamos a buscar el valor de $\theta$ que maximiza dicha funcion, luego $\hat{\theta} = \hat{\theta}(\underline{X})$.\\
Si $\Theta$ es un subconjunto abierto tal que el soporte de $f_{\theta}(\underline{x})$ no depende de $\theta$, como la funcon logaritmo es monotona creciente, maximizar $\mathcal{L}(\theta)$ es lo mismo que maximizar $log(\mathcal{L}(\theta))$. Luego, el EMV verificara que:
\begin{equation*}
    \frac{d}{d\theta} ln(\mathcal{L}(\theta)) = 0
\end{equation*}
\subsection{Principio de invariancia}
Supongamos que $\lambda = q(\theta)$ es una funcion biunivoca de $\theta$. Si $\hat{\theta}$ es el EMV de $\theta$ entonces $\hat{\lambda} = q(\hat{\theta})$ sera el EMV de $\lambda$.
\subsection{Bondad de los estimadores}
Dada $X_{1},...,X_{n} \backsim^{iid} F_{\theta}(x), \hspace{8px} \theta \in \Theta$ una m.a. Estimamos $\theta$ por $\hat{\theta}$. El riesgo de estimar $\theta$ con $\hat{\theta}$ se mide con el error cuadratico medio.
\begin{equation*}
    R(\theta,\hat{\theta}) = ECM(\hat{\theta}) = E [(\theta - \hat{\theta})^{2}]
\end{equation*}
Diremos que un estimador optimo para $\theta$ sera $\hat{\theta}$ tal que 
\begin{equation*}
    ECM(\hat{\theta}^{k}) \leq ECM(\hat{\theta}), \forall \hat{\theta}
\end{equation*}
\subsection{Estimador Insesgado}
Un estimador es insesgado para $\theta$ si:
\begin{equation*}
    E_{\theta}(\hat{\theta}) = \theta, \hspace{8px} \forall \theta \in \Theta
\end{equation*} 
En caso contrario, diremos que el estimador es sesgado, y definiremos su sesgo como:
\begin{equation*}
    B(\hat{\theta}) = E_{\theta}(\hat{\theta}) - \theta
\end{equation*}
\subsubsection{Propiedad}
Dado un estimador de $\theta$, se tiene que:
\begin{equation*}
    ECM(\hat{\theta}) = Var_{\theta}(\hat{\theta}) + B(\hat{\theta})^{2}
\end{equation*}
Por lo tanto, si es insesgado, $B = 0$ y $ECM(\hat{\theta}) =  Var_{\theta}(\hat{\theta})$
\subsubsection{Estimador asintoticamente insesgado}
Un estimador es asintoticamente insesgado si:
\begin{equation*}
    lim_{n\rightarrow \infty} E_{\theta}(\hat{\theta}) = \theta, \hspace{8px} \forall \theta \in \Theta
\end{equation*}
\subsection{Estimador consistente}
Dada una sucesion de estimadores $\hat{\theta}_{n}$ de $\theta$, decimos que $T=\hat{\theta}$ es (debilmente) consistente si $\forall \hspace{8px}\varepsilon > 0$:
\begin{equation*}
    P_{\theta}(|T - \theta| > \varepsilon) \rightarrow_{n\rightarrow \infty} 0
\end{equation*}
\subsubsection{Teorema}
Sea una sucesion de estimadores de $\hat{\theta}_{n}$ de $\theta$. Si $Var_{\theta}(\hat{\theta}) \rightarrow 0$ y $E_{\theta}(\hat{\theta}) \rightarrow \theta$.
entonces $\hat{\theta}_{n}$ es debilmente consistente.
\subsubsection{Consistencia media cuadratica}
\begin{equation*}
    lim_{n \rightarrow \infty}ECM(\hat{\theta}) = 0, \hspace{8px} \forall \theta \in \Theta
\end{equation*}
\subsection{Estimadores asintoticamente normales}
Se dice que $\hat{\theta}_{n}$ es una sucesion de estimadores asintoticamente normales si $\sqrt{n}(\hat{\theta}_{n} - q(\theta))$
converge en distribucion a una normal con media cero y varianza $\frac{q'(\theta)^{2}}{T(\theta)}$.\\
$I(\theta)$ se llama \color{orange} Numero de informacion de fisher \color{black} y se calcula como:
\begin{equation*}
    I(\theta) = E[(\frac{d}{d\theta}ln(f_{\theta}(X)))^{2}] = - E[\frac{d^{2}}{d\theta^{2}}ln(f_{\theta}(X))]
\end{equation*}
(vale solo para familias regulares)
\subsubsection{Teorema}
Bajo ciertas condiciones muy generales, sea $\hat{\theta}_{n}(\underline{X})$ un EMV de $\theta$ \underline{consistente} y sea $q(\theta)$ derivable con $q'(\theta) \neq 0, \hspace{8px} \forall \theta$, entonces
$q(\hat{\theta}_{n})$ es asintoticamente normal para estimar $q(\theta)$.\\
Si $\sqrt{n}\sqrt{I(\theta)} \cdot (\hat{\theta}_{n}- \theta) \backsim^{a} \mathcal{N}(0,1)$ y $\hat{\theta}$ es un estimador consistente para $\theta$ (todo esto ocurrira con los EMV), entonces vale que:\\
\begin{equation*}
    \sqrt{n}\sqrt{I(\hat{\theta}_{n})} \cdot (\hat{\theta}_{n}- \theta) \backsim^{a} \mathcal{N}(0,1)
\end{equation*}
\section{Distribuciones continuas importantes}
\subsection{Chi-Cuadrado}
La V.A. X tiene una distribucion $\mathcal{X}^{2}$ de parametro $v$ (grados de libertad) si su densidad esta dada por:
\begin{equation*}
    f_{X}(x) = \frac{1}{\Gamma(v/2)} (\frac{1}{2})^{v/2} \cdot x^{\frac{v}{2}-1} e^{-x/2} \mathbb{1} {x>0}
\end{equation*}
Se puede observar que coincide con una variable con distribucion $\Gamma(\frac{v}{2},\frac{1}{2})$. De ahi deducimos facilmente que $E(X)=v$ y $Var(X) =2v$.\\
\subsubsection{Teorema}
Si $x_{1},...,X_{n}, i=1,...,n$, entonces $Y= \sum_{i=1}^{n}X_{i}$ tendra distribucion $\mathcal{X}^{2}_{v}$, con $v =\sum_{i=1}^{n} V_{i} $.
\subsubsection{Corolario}
Se llama distribucion $\mathcal{X}^{2}$ con $n$ grados de libertad a la distribucion de $U = \sum_{i=1}^{n} Z_{i}^{2}$ donde $Z_{i},...,Z_{n} \backsim^{iid} \mathcal{N}(0,1)$.
\subsection{t de Student}
Sean $Z \backsim \mathcal{N}(0,1)$ y $U \backsim \mathcal{X}^{2}$, entonces si $Z$ y $U$ son independientes, $T= \frac{Z}{\sqrt{U/n}} \backsim t_{n}$.
\subsection{Distribucion F de Fisher-Snedecor}
Sean $U$ y $V$ dos variables aleatorias indep. con distribucion $\mathcal{X}^{2}$ de $n_{1}$ y $n_{2}$ g.l. respectivamente.\\
Entonces:
\begin{equation*}
    F=\frac{U/n_{1}}{V/n_{2}} \backsim \mathcal{F}_{n_{1},n_{2}}
\end{equation*}
\subsection{Teorema}
Sean $X_{1},...,X_{n} \backsim^{iid} \mathcal{N}(\mu,\sigma^{2})$
\begin{enumerate}
    \item $Z=\sqrt{n} (\frac{\bar{X} - \mu}{\sigma}) \backsim \mathcal{N}(0,1)$.
    \item $W = \sum_{i=1}^{n}\frac{(X_{i}-\bar{X})^{2}}{\sigma^{2}} \backsim \mathcal{X}_{n-1}^{2}$.
    \item $w$ y $Z$ son independientes.
    \item Si $S^{2} = \sum_{i=1}^{n} \frac{(X_{i}-\bar{X})^{2}}{n-1} $ entonces $T = \sqrt{n}\frac{(\bar{X} - \mu)}{S} \backsim t_{n-1}$
\end{enumerate}
\section{Test de hipotesis}
Una hipotesis es una suposicion o conjetura sobre la naturaleza, cuyo valor de verdad o falsedad no se conoce. Una hipotesis estadistica es una hipotesis sobre una o mas poblaciones estadisticas o sobre un fenomeno aleatorio.
\begin{enumerate}
    \item Hipotesis estadistica $\rightarrow$ Poblacion.
    \item Analisis $\rightarrow$ Muestra.
\end{enumerate}
\subsection{Ensayo de hipotesis} 
Procedimiento que se sigue para tratar de averiguar si una hipotesis es verdadera o falsa.
Siempre se van a presentar dos hiportesis:
\begin{enumerate}
    \item $H_{1}:$ (Hipotesis de investigador) Hipotesis alternativa.
    \item $H_{0}:$ Hipotesis nula. Objeto de ensayo. (Se formula con la intension de ser rechazada)
\end{enumerate}
\subsection{Tipos de errores}
\begin{enumerate}
    \item Error de tipo $I$: Se comete cuando se rechaza una hipotesis nula que era verdadera. Debe tener MUY baja probabilidad.
    \item Error de tipo $II$: Se comete cuando no se rechaza una hipotesis nula que era falsa.
\end{enumerate}
[E$I$ es mas grave que E$II$]
\subsection{Potencia del test}
Probabilidad de rechazar la hipotesis nula.
\subsection{Test de hipotesis}
Es una regla de decision entre $H_{0}$ y $H_{1}$, y la expresamos como una funcion de la muestra aleatoria $\delta(\underline{X})$ que puede tomar los valores 0 o 1.
Si $\delta(\underline{X}) = 1$ se rechaza $H_{0}$, y en caso contrario no se rechaza.\\
Sea $\underline{X} = (X_{1},...,X_{n})$ una m.a. de una poblacion con distribucion $F_{\theta} (x), \hspace{8px} \theta \in \Theta $.
Sean $\Theta_{1}$ y $\Theta_{2}$ tales que $\Theta_{1} \cup \Theta_{2} = \Theta$ y $\Theta_{1} \cap  \Theta_{2} = \emptyset $. Un test para este problema es una regla de decision basada en $\underline{X}$ para decidir entre 2 hipotesis.
\begin{equation*}
    H_{0}: \theta \in \Theta_{1} \hspace{16px} vs \hspace{16px} H_{1}: \theta \in \Theta_{2}
\end{equation*}
Entonces:
\begin{enumerate}
    \item $P('\text{Error I}') = P_{\theta}('\text{Rechazar }H_{0}'), \theta \in \Theta_{1} $
    \item $P('\text{Error II}') = P_{\theta}('\text{No rechazar }H_{0}'), \theta \in \Theta_{2} $
\end{enumerate}
Y la potencia del test es $\Pi_{\delta}(\theta) = P_{\theta}('\text{Rechazar }H_{0}') = P_{\theta}(\delta(\underline{X}) =1 ) = E_{\theta}\delta(\underline{X})$.\\
OBS:
\begin{enumerate}
    \item $P('\text{Error I}') = \Pi_{\delta}(\theta), \hspace{8px} \theta \in \Theta_{1}$
    \item $P('\text{Error II}') = 1- \Pi_{\delta}(\theta), \hspace{8px} \theta \in \Theta_{2}$
\end{enumerate}
\subsection{Nivel de significacion del test}
Es la maxima probabilidad de cometer un error de tipo $I$.
\begin{equation*}
    \alpha = sup_{\theta \in \Theta_{1}} \Pi_{\delta}(\theta)
\end{equation*}
Se llama \color{violet} $p$-valor \color{black} de un test al menor nivel de significacion para el cual se rechaza $H_{0}$, para una observacion dada.
(Es la probabilidad de encontrar un valor tan o mas extremo que el que se encontro con la muestra observada).\\
Llamaremos curva caracteristica:
\begin{equation*}
    \beta(\theta) = P_{\theta}('\text{Error II}') = 1- \Pi_{\delta}(\theta), \hspace{8px} \theta \in \Theta_{2}
\end{equation*}
\subsection{Test del cociente de verosimilitud}
\subsubsection{Test para hipotesis simple vs hipotesis simple}
Es el caso cuando tenemos $\Theta_{1}$ y $\Theta_{2}$ con un solo elemento cada una:
\begin{equation*}
    H_{0}: \theta = \theta_{1} \hspace{16px} vs. \hspace{16px} H_{1}: \theta = \theta_{2}
\end{equation*}
Regla de decision (Test):
\begin{equation*}
    \delta(\underline{x})= \left\{ \begin{array}{lcc}
        1 &   si  & \frac{f_{\theta_{2}}(\underline{X})}{f_{\theta_{1}}(\underline{X})} > K_{\alpha} \\
        0 &  si & no
        \end{array}
    \right.
\end{equation*}
Dada un $\alpha$ fijo, debemos hallar $K_{\alpha}$ que cumpla:
\begin{equation*}
    \alpha = P_{\theta_{1}}((\delta(\underline{X}) = 1))
\end{equation*}
Supongamos que $X_{1},...,X_{n} \backsim^{iid} \mathcal{N}(\mu,\sigma^{2})$ nuestra m.a., y que por alguna razon razon conocemos $\sigma^{2}$.
\begin{equation*}
    H_{0}: \mu = \mu_{1} \hspace{16px} vs. \hspace{16px} H_{1}: \mu = \mu_{2}
\end{equation*}
Desarrollando el cociente de verosimilitud, aplicando logaritmo y desarrollando cuadrados:
\begin{equation*}
    \delta(\underline{x})= \left\{ \begin{array}{lcc}
        1 &   si  & \sum_{i=1}^{n}(X_{i}) > K'_{\alpha} \\
        0 &  si & no
        \end{array}
    \right.
\end{equation*}
Y para hallar el valor de $K'_{\alpha}$ usamos la $2^{o}$ condicion.
\begin{equation*}
    \alpha = P_{\mu_{1}}(\delta(\underline{X}) =1) = P_{\mu_{1}}(\sum_{i=1}^{n}(X_{i}) > K'_{\alpha}) = P_{\mu_{1}}(\frac{\sum_{i=1}^{n}(X_{i})-n \cdot \mu_{1}}{\sqrt{n\sigma^{2}}}< z _{\alpha})
\end{equation*}
Entonces el test con nivel de significacion $\alpha$.
\begin{equation*}
    \delta(\underline{x})= \left\{ \begin{array}{lcc}
        1 &   si  & \frac{\sum_{i=1}^{n}(X_{i})-n \cdot \mu_{1}}{\sqrt{n\sigma^{2}}}< z _{\alpha} \\
        0 &  si & no
        \end{array}
    \right.
\end{equation*}
OBS: $\delta(\underline{X})$ depende de $\alpha, n$ la m.a. y el valor del parametro. Bajo $H_{0}$ la regla sera la misma si $H_{1}: \mu<\mu_{1}$.\\
La funcion potencia para este caso:
\begin{eqnarray*}
    \Pi_{\delta}(\mu) &= P_{\mu}(\delta(\underline(X))=1)\\
    &= P_{\mu} (\frac{\sum_{i=1}^{n}(X_{i})-n \cdot \mu_{1}}{\sqrt{n\sigma^{2}}}< z _{\alpha})\\
    &=P_{\mu} (\sum_{i=1}^{n}(X_{i})< z _{\alpha}) \cdot \sqrt{n\sigma^{2}} + n \cdot \mu_{1}\\
    &= \Phi(z_{\alpha} - \frac{\sqrt{n}}{\sigma}(\mu -\mu_{1}) )
\end{eqnarray*}
\subsection{Propiedad}
Sea $\underline{X} = (X_{1},...,X_{n})$ una m.a. con distribucion perteneciente a una familia exponencial, luego
\begin{enumerate}
    \item Si $c(\theta)$ es creciente, el test para 
    \begin{equation*}
        H_{0}: \theta \leq \theta_{1} \hspace{16px} vs \hspace{16px} \theta > \theta_{1}
    \end{equation*}
    Sera
    \begin{equation*}
        \delta(\underline{x})= \left\{ \begin{array}{lcc}
        1 &   si  & T > K_{\alpha} \\
        0 &  si & T \leq K_{\alpha}
        \end{array}
        \right.
    \end{equation*}
    Sabiendo que $T(X) = r(\underline{X})$. Aclaracion: La uniforme entra en este caso.\\
    Que para un nivel $\alpha$ dado se tendra $\alpha = P_{\theta_{1}} (\delta(\underline{X})=1 )$
    \item Si $c(\theta)$ es decreciente, el test para 
    \begin{equation*}
        H_{0}: \theta \leq \theta_{1} \hspace{16px} vs \hspace{16px} H_{1}:\theta > \theta_{1}
    \end{equation*}
    Sera
    \begin{equation*}
        \delta(\underline{x})= \left\{ \begin{array}{lcc}
            1 &   si  & -T > K_{\alpha} \\
            0 &  si & -T \leq K_{\alpha}
            \end{array}
            \right.
    \end{equation*}
    Que para un nivel $\alpha$ dado se tendra $\alpha = P_{\theta_{1}} (\delta(\underline{X})=1 )$.\\
    En todos casos los signos $(<,>,\leq,\geq)$  se pueden dar vuelta, TODOS.
\end{enumerate}
\subsection{}

\end{document}
